\documentclass[11pt,a4paper]{article}
% See geometry.pdf to learn the layout options. There are lots.
\usepackage{geometry}
\geometry{left = 3cm, right = 3cm, top = 3cm, bottom = 3cm}
% Activate to begin paragraphs with an empty line rather than an indent
\usepackage[parfill]{parskip}
\usepackage[table]{xcolor}
\usepackage{courier,multirow,fancyhdr}
\usepackage{float,amsmath,graphicx,framed,subfiles}
\usepackage{amssymb,subcaption,textcomp,listings}
\usepackage{booktabs,epstopdf,caption,units,rotating}
\usepackage[framed,numbered]{matlab-prettifier}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
% hyperref should be loaded last
\usepackage[
    colorlinks=true,
    pdfencoding=auto,
    pdfauthor={Oliver Lee},
    pdftitle={WB2301-5 System Identification and Parameter Estimation:
    Assignment 5 - Subspace Identification},
    pdftex
]{hyperref}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\mcode}[1]{
    \lstinline[
        style=Matlab-editor,
        basicstyle=\mlttfamily,
    ]{#1}
}

\frenchspacing

\pagestyle{fancy}
\fancyhead{}
\fancyhead[R]{Lee}
\fancyhead[L]{Assignment 5}


\title{WB2301-5 System Identification and Parameter Estimation \\
Assignment 5 - Subspace Identification}
\author{Oliver Lee}
\date{\today}
\graphicspath{ {images/} }

\begin{document}
\maketitle

\section{Identification of autonomous systems}

% 1a
\subsection{System trajectories}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{datamatrix1a.eps}
    \caption{Output Data Matrix for Varying Initial Conditions}
    \label{fig:datmat}
\end{figure}
The Hankel matrix of output data, $Y_{0,s,N}$ of a system is shown in
\autoref{fig:datmat} for three different initial conditions. We see that a
change in initial condition changes the initial position in the data space, but
all three trajectories converge to a unique data space trajectory for the
system.  Although the data space is 3-dimensional, the output of the system
spans only a 2-dimensional space, which is illustrated as the trajectories lie
in a plane.

% 1b
\subsection{Singular value decomposition}
The broken lines shown in \autoref{fig:datmat} come from the singular value
decomposition (SVD) of the Hankel matrix of the output data. The SVD of
$Y_{0, s, N}$ is written as:
\begin{equation}
    \label{eq:svd}
    Y_{0, s, N} = U \Sigma V^T
\end{equation}
Plotted are the columns of $U$, which form a basis for the output vector space,
scaled by the singular values of $\Sigma$. In all three initial conditions, the
third singular value is on the order of machine precision, and these scaled
basis vectors span two dimensions: the system output subspace.

% 1c
\subsection{Varying system parameters}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{datamatrix1c.eps}
    \caption{Output Data Matrix for Varying System Parameters}
    \label{fig:datmat2}
\end{figure}
Trajectories for various system parameters ($M$, $B$, $K$) are shown in
\autoref{fig:datmat2}. The trajectory plane differs with system parameters.
However, if only damping $B$ is changed, the trajectory plane remains the same,
but the oscillations about the convergence point reduce (increase) with an
increase (decrease) of damping value. As this system is linear and stable, the
trajectories converge at zero. The trajectory plane is related to the
natural frequency of the system $\omega_n$, which is expressed as:
\begin{equation}
    \label{eq:natfreq}
    \omega_n^2 = \frac{k}{m}
\end{equation}
As changing damping does not affect the natural frequency, the trajectory plane
will also remain unchanged.

% 1d
\subsection{Comparison of original and identified systems}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{svd1d.eps}
    \caption{System Singular Values}
    \label{fig:svd}
\end{figure}
The singular values for the three sets of system parameters (and associated
trajectories as seen in \autoref{fig:datmat2}) are displayed in
\autoref{fig:svd}. For all three configurations, the last singular value is
small (\autoref{tab:sv}) and close to machine precision $\epsilon$. Running
\mcode{eps} returns:
\begin{lstlisting}
>> eps
ans =
    2.220446049250313e-16
\end{lstlisting}

\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|}
        \hline
        $(M, B, K)$ & $\sigma_1$ & $\sigma_2$ & $\sigma_3$ \\
        \hline
        $(0.1, 0.5, 450)$ & $ 2.087734061246928 $ &
            $ 1.186284234703669 $ & $ 1.494061250544577 \times 10^{-15} $ \\
        $(0.5, 1, 150)$ & $ 6.095624673944504 $ &
            $ 0.816372776568143 $ & $ 1.176216626686808 \times 10^{-15} $ \\
        $(0.1, 5, 450)$ & $ 0.897841350466776 $ &
            $ 0.302086412052466 $ & $ 5.202183291262978 \times 10^{-17} $ \\
        \hline
    \end{tabular}
    \caption{Singular Values for Varying System Parameters}
    \label{tab:sv}
\end{table}

Using a system dimension of $n = 2$, we extract the discrete time system
matrices and calculate the eigenvalues, which are shown in
\autoref{tab:syseig}. As the eigenvalues vary by a small amount (on the order
of $\epsilon$), the dynamics of the original and identified system are
identical.

%\begin{table}
%    \centering
%    \begin{tabular}{|l|r|r|}
%        \hline
%        \nonumber & $\lambda_1$ & $\lambda_2$ \\
%        \hline
%        original &
%            \shortstack[r]{$ 0.764254358051321 + $ \\
%                $ 0.605924665862248i $} &
%            \shortstack[r]{$ 0.764254358051321 - $ \\
%                $ 0.605924665862248i $} \\
%        identified &
%            \shortstack[r]{$ 0.764254358051322 + $ \\
%                $ 0.605924665862246i $} &
%            \shortstack[r]{$ 0.764254358051322 - $ \\
%                $ 0.605924665862246i $} \\
%        \hline
%    \end{tabular}
%    \caption{Eigenvalues for Original and Identified Systems}
%    \label{tab:syseig}
%\end{table}
\begin{table}
    \centering
    \begin{tabular}{|l|r|r|}
        \hline
        \nonumber & original & identified \\
        \hline
        $\lambda_1, \lambda_2 $ &
            $ 0.764254358051321 \pm
                0.605924665862248i $ &
            $ 0.764254358051322 \pm
                0.605924665862246i $ \\
        \hline
    \end{tabular}
    \caption{Eigenvalues for Original and Identified Systems}
    \label{tab:syseig}
\end{table}

%1e
\subsection{Differences in response of orignal and identified systems}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{output1e.eps}
    \caption{System Output}
    \label{fig:output}
\end{figure}
The response of the autonomous system is shown in \autoref{fig:output} for the
initial condition of $ x_0 = \begin{pmatrix}1 & 1\end{pmatrix}^T $. The data
equation for an autonomous system is given by:
\begin{equation}
    \label{eq:dataeq}
    Y_{i, s, N} = \mathcal{O}_s X_{i, N}
\end{equation}
where $Y_{i, s, N}$ is the Hankel matrix of the output data, $\mathcal{O}_s$ is
the extended observability matrix, and $X_{i, N}$ is the state matrix and are
defined as:
\begin{align}
    Y_{i, s, N} &=
        \begin{bmatrix}
            y(i) & y(i + 1) & \cdots & y(i + N - 1) \\
            y(i + 1) & y(i + 2) & \cdots & y(i + N) \\
            \vdots & \vdots & \ddots & \vdots \\
            y(i + s - 1) & y(i + s) & \cdots & y(i + N + s - 2) \\
        \end{bmatrix} \label{eq:yhankel} \\
    \mathcal{O}_s &= \begin{bmatrix}
        C \\ CA \\ CA^2 \\ \vdots \\ CA^{s - 1}
        \end{bmatrix} \label{eq:extobs} \\
    X_{i, N} &= \begin{bmatrix} x(i) & x(i + 1) &
        \cdots & x(i + N - 1) \end{bmatrix} \label{eq:xhankel}
\end{align}
Setting this equal to \autoref{eq:svd}, and because the column space of
$\mathcal{O}_s$ equals that of $Y_{i, s, N}$, we can choose the following
relation:
\begin{equation}
    \label{eq:uo}
    U = \mathcal{O}_s T
\end{equation}
as $U$ spans the same space as $Y_{i, s, N}$ from the properties of the SVD and
T is a similarity transformation.

As the identified system is similar (but not equal) to the original system, the
state representation differs. This can be seen by the output of the simulated
the system given the same initial condition (plots $y0$ and $yi$) in
\autoref{fig:output}.

Given our choice of relation between the SVD and data equation in
\autoref{eq:uo}, this can be extended to the $V$ and $X_{i, N}$ matrices:
\begin{equation}
    \label{eq:vx}
    \Sigma V^T = T^{-1} X_{i, N}
\end{equation}
If we want to use the same initial condition, the first column of
\autoref{eq:vx} gives the transformed state, and results in an identical
outputs of the original and identified systems as seen (plots $y0$ and $yi_T$)
in \autoref{fig:output}.

%1f
\subsection{Effect of noise}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{output1f.eps}
    \caption{System Output with Noise}
    \label{fig:output1f}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{datamatrix1f.eps}
    \caption{Output Data Matrix with Noise}
    \label{fig:datmat1f}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{svd1f.eps}
    \caption{System Singular Values with Noise}
    \label{fig:svd1f}
\end{figure}
The effect of adding white noise with variance $\sigma_n = 1.0 \times 10^{-2}$
is shown in \autoref{fig:output1f}, \autoref{fig:datmat1f}, and
\autoref{fig:svd1f}. As the mass converges to the equilibirum point, the effect
of output noise becomes more visible in both the system response and in the
data space. The third singular value is now much larger than $\epsilon$ and it
is not clear that the state is 2-dimensional. However, if the system state is
taken to be 2, then the identified system closely matches the original system
and the output is reproduced with little error. This is shown in
\autoref{fig:output1f}, where $y_{id}$ and $yk_{id}$, the two identified
systems, overlap the $y0$.

%1g
\subsection{Improving estimates with noisy data}
TODO: Increasing s does increase the difference the 2nd and 3rd singular
values. Decreasing N increases the gap between 2nd and 3rd singular values
since the output data is less affected by noise the closer the further is it
from 0.

%1h
\subsection{Identification of a 4th order system}
Deriving the equations of motion for a standard double mass-spring-damper
system results in the following continuous state space:
\begin{align}
    \dot{x} &=
        \begin{bmatrix}
            -\frac{c_1+c_2}{m_1} & \frac{c_2}{m_1} &
                -\frac{k_1+k_2}{m_1} & \frac{k_2}{m_1} \\
            \frac{c_2}{m_2} & -\frac{c_2}{m_2} &
                \frac{k_2}{m_2} & -\frac{k_2}{m_2} \\
            1 & 0 & 0 & 0 \\
            0 & 1 & 0 & 0 \\
        \end{bmatrix} x  \\
    y &= \begin{bmatrix} 0 & 0 & 1 & 0 \end{bmatrix} x
\end{align}

After conversion to a discrete system, and using paramter values
\mbox{$ m_1 = m_2 = 0.1 $}, \mbox{$ c_1 = c_2 = 0.5 $},
\mbox{$ k_1 = k_2 = 450 $}, the four eigenvalues of
are calculated and displayed in \autoref{tab:sys4eig}. Adding white noise with
variance $\sigma_n = 1.0 \times 10^{-2}$ to the system output and repeating the
identification steps with $s = 5$ and $N = 100$ results in a good estimate of
the original system. The discrete eigenvalues for the identified system are
also displayed in \autoref{tab:sys4eig}. TODO: The values aren't that close

\begin{table}
    \centering
    \begin{tabular}{|l|r|r|}
        \hline
        \nonumber & original & identified \\
        \hline
        $ \lambda_1, \lambda_2 $ &
            \shortstack[r]{$ 0.438627174339038 \pm
                 0.827593022905266i $} &
            \shortstack[r]{$ 0.422457129755468 \pm
                 0.799601319875711i $} \\

        $ \lambda_3, \lambda_4 $ &
            \shortstack[r]{$ 0.906626944382392 \pm
                0.398886575632521i $} &
            \shortstack[r]{$ 0.907374428491475 \pm
                0.401684694233408i $} \\

        \hline
    \end{tabular}
    \caption{Eigenvalues for Original and Identified 4th Order System}
    \label{tab:sys4eig}
\end{table}

\section{Identification with general inputs}

% 2a
\subsection{Identification using impulse input}
The full form of the data equation is:
\begin{equation}
    \label{eq:fulldataeq}
    Y_{i, s, N} = \mathcal{O}_s X_{i, N} + \mathcal{T}_s U_{i, s, N}
\end{equation}
where $U_{i, s, N}$ is a Hankel matrix of the input data and is expressed as:
\begin{equation}
    \label{eq:uhankel}
    U_{i, s, N} =
        \begin{bmatrix}
            u(i) & u(i + 1) & \cdots & u(i + N - 1) \\
            u(i + 1) & u(i + 2) & \cdots & u(i + N) \\
            \vdots & \vdots & \ddots & \vdots \\
            u(i + s - 1) & u(i + s) & \cdots & u(i + N + s - 2) \\
        \end{bmatrix}
\end{equation}
for $i = 0$  and $\mathcal{T}_s$ is the impulse reponse matrix.
If the first column of $Y_{0, s, N}$ is ignored, the data equation simplifies
to
\begin{equation}
    \label{eq:simpdataeq}
    Y_{1, s, N} = \mathcal{O}_s X_{1, N}
\end{equation}
as $U_{1, s, N} = 0$ with an impulse input ($u(0) = 1, \quad u(i) = 0 \quad
\forall i \neq 0$).
As the simplified data equation is equivalent to the autonomous system response
(\autoref{eq:dataeq}), the same process can be used to determine system
matrices $A$ and $C$.

% 2b
\subsection{Estimation of B, D}
With zero initial state and impulse input and use of the difference equation:
\begin{equation}
    \label{eq:diffeq}
    x(i + 1) = Ax(i) + Bu(i)
\end{equation}

$X_{1, N}$ can be written as:
\begin{equation}
    \label{eq:simpxhankel}
    X_{1, N} = \begin{bmatrix}
        B & AB & A^2B & \cdots & A^{N-1}B
    \end{bmatrix}
\end{equation}

Using \autoref{eq:vx}, we find:
\begin{align}
    \Sigma V^T &= T^{-1} \begin{bmatrix}
        B & AB & A^2B & \cdots & A^{N-1}B \end{bmatrix} \\
    &= \begin{bmatrix}
        B_T & A_TB_T & {A_T}^2B_T & \cdots & {A_T}^{N-1}B_T \end{bmatrix}
\end{align}
Thus, $B_T$ is the first column of $\Sigma V^T$.

For $i > 1$, the first element of $X_{i, N} = A^{i - 1}B$ instead of simply
$B$, and we have the equation:
\begin{equation}
    (\Sigma V^T)(:, 1) = {A_T}^{i - 1}B_T
\end{equation}
We can solve the linear system for $B_T$ after computing ${A_T}^{i-1}$.

% 2c
\subsection{Effect of noise on estimate of D}
$D$ is estimated by the following Matlab code:
\begin{lstlisting}
Did = yk(1);
\end{lstlisting}
As $D$ is simply a single element of the output, any noise in the output
propagates directly to the estimate.

% 2d
\subsection{Effect of White Noise Excitation on Data Space}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{dataspace2d.eps}
    \caption{Data Space for White Noise Input}
    \label{fig:dataspace2d}
\end{figure}
With a white noise input, the system is persistently excited and the trajectory
does not converge to zero. This can be seen in plot $YsN$ of
\autoref{fig:dataspace2d}.

% 2e
\subsection{Estimation of B, D with white noise input}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{output2e.eps}
    \caption{System Output for White Noise Input}
    \label{fig:output2e}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{outputzoom2e.eps}
    \caption{Zoomed System Output for White Noise Input}
    \label{fig:outputzoom2e}
\end{figure}
$YsNP$ is plotted in \autoref{fig:dataspace2d}. The least squares routine is used
to estimate B and D and the output for the identified system is plotted in
\autoref{fig:output2e} and a section is zoomed in \autoref{fig:outputzoom2e}.
The original system output is labeled $y0$ and the identified system $y_{id}$.
The plots show that the identified system is a good estimate of the original.

% 2f
\subsection{Removing influence of input on output data matrix}
In identification of autonomous systems, the column space of $\mathcal{O}_s$ is
equal to the column space of $Y_{i, s, N}$, which then allows for matrices $A$
and $C$ to be estimated. When using general inputs, the influence of the input
on the column space of $Y_{i, s, N}$ for obtain a matrix with column space
equal to $\mathcal{O}_s$. With a right multiplication of the data equation
(\autoref{eq:fulldataeq}) by the orthogonal projection onto the column space of
$U_{0, s, N}$, $\Pi^\perp_{U_{0,s,N}}$:
\begin{equation}
    \label{eq:yuperp}
    Y_{0, s, N} \Pi^\perp_{U_{0,s,N}} =
        \mathcal{O}_s X_{0, N} \Pi^\perp_{U_{0,s,N}} 
\end{equation}
where 
\begin{equation}
    \label{eq:uoperp}
    \Pi^\perp_{U_{0,s,N}} =
        I_N - U^T_{0,s N}(U_{0, s, N}U^T_{0,s,N})^{-1} U_{0,s,N}
\end{equation}
and
\begin{equation*}
    U_{0,s,N} \Pi^\perp_{U_{0,s,N}} = 0
\end{equation*}
It can then be shown with the use of Sylvester's inequality that
\begin{equation*}
    \text{range}(Y_{0,s,N} \Pi^\perp_{U_{0,s,N}}) =
        \text{range}(\mathcal{O}_s)
\end{equation*}
As we have a matrix with column space equal to the extended observability
matrix, the same process for identification of autonomous systems can be used.

% 2g
\subsection{Identification with white noise excitation and output noise}
Adding white noise ($\sigma_n = 10^{-3}$) to the output data and using/fr
\mbox{$s = 25$}, \mbox{$N = 400$} still yields a good estimate of the system
matrices. The output with noise and output for the identified system (plots
$yk$ and $yk_{id}$ respectively) are shown in \autoref{fig:output2e} and
\autoref{fig:outputzoom2e}.

% 2h
\subsection{Identification with white noise for MIMO systems}
Using a standard triple mass-spring-damper system, with input forces at each
mass, we have the following continuous state space representation:
\begin{align}
    \dot{x} &=
        \begin{bmatrix}
            -\frac{c_1+c_2}{m_1} & \frac{c_2}{m_1} & 0 &
                -\frac{k_1+k_2}{m_1} & \frac{k_2}{m_1} & 0 \\
            \frac{c_1}{m_2} & -\frac{c_2 + c_3}{m_2} & \frac{c_3}{m_2} &
                \frac{k_1}{m_2} & -\frac{k_2 + k_3}{m_2} & \frac{k_3}{m_2} \\
            0 & \frac{c_3}{m_3} & -\frac{c_3}{m_3} &
                0 & \frac{k_3}{m_3} & -\frac{k_3}{m_3} \\
            1 & 0 & 0 & 0 & 0 & 0 \\
            0 & 1 & 0 & 0 & 0 & 0 \\
            0 & 0 & 1 & 0 & 0 & 0
        \end{bmatrix} x
        +
         \begin{bmatrix}
             \frac{1}{m_1} & 0 & 0 \\
             0 & \frac{1}{m_2} & 0 \\
             0 & 0 & \frac{1}{m_3} \\
             0 & 0 & 0 \\
             0 & 0 & 0 \\
             0 & 0 & 0
         \end{bmatrix} u \\
        u \\
    y &= \begin{bmatrix}
        0 & 0 & 0 & 1 & 0 & 0 \\
        0 & 0 & 0 & 0 & 1 & 0 \\
        0 & 0 & 0 & 0 & 0 & 1
        \end{bmatrix} x
\end{align}
where
\begin{equation*}
    x =
        \begin{bmatrix}
            \dot{x_1} \\ \dot{x_2} \\ \dot{x_3} \\ x_1 \\ x_2 \\ x_3
        \end{bmatrix} \\
        \qquad
    u =
        \begin{bmatrix}
            u_1 \\ u_2 \\ u_3
        \end{bmatrix} \\
        \qquad
    y =
        \begin{bmatrix}
            y_1 \\ y_2 \\ y_3
        \end{bmatrix}
\end{equation*}
With
\mbox{$ m_1 = m_2 = m_3 = 0.1 $},
\mbox{$ c_1 = c_2 = c_3 = 0.5 $},
\mbox{$ k_1 = k_2 = k_3 = 450 $},
we find the eigenvalues of the continuous system all lie in the right half
plane and the system is stable. The system eigenvalues are tabulated in
\autoref{tab:sys6eig}.
\begin{table}
    \centering
    \begin{tabular}{|l|r|}
        \hline
        $ \lambda_1, \lambda_2 $ & $ -0.4952 \pm 29.8502i $ \\
        $ \lambda_3, \lambda_4 $ & $ -3.8874 \pm 83.5596i $ \\
        $ \lambda_5, \lambda_6 $ & $ -8.1174 \pm 120.6048i $ \\
        \hline
    \end{tabular}
    \caption{Eigenvalues for Continuous Time 6th Order System}
    \label{tab:sys6eig}
\end{table}
After converting the continuous time system to a discrete time system, Matlab
function \mcode{getshp.p} can be used for system identification. Input and
output time series, with and without noise, as well as bode plots of the
original and identified systems are shown in \autoref{fig:input2h},
\autoref{fig:output2h}, \autoref{fig:bode2h} using parameter values \mbox{$s =
20$}, \mbox{$N = 1000$} and noisy inputs/outputs.
Although system eigenvalues differ (see \autoref{sys6deig}), the output of the
identified system closely matches the clean output of the original system as
seen in \autoref{fig:output2h}.
\begin{table}
    \centering
    \begin{tabular}{|l|r|r|}
        \hline
        \nonumber & original & identified \\
        \hline
        $ \lambda_1 $ & $ -0.9400 - 0.1484i $ & $ -0.3715 - 0.7552i $ \\
        $ \lambda_2 $ & $ -0.9400 + 0.1484i $ & $ -0.3715 + 0.7552i $ \\
        $ \lambda_3 $ & $ -0.3263 - 0.5943i $ & $ -0.3333 $ \\
        $ \lambda_4 $ & $ -0.3263 + 0.5943i $ & $  0.6162 $ \\
        $ \lambda_5 $ & $ 0.3885 - 0.2152i $ & $ 0.7874 - 0.3892i $ \\
        $ \lambda_6 $ & $ 0.3885 + 0.2152i $ & $ 0.7874 + 0.3892i $ \\
        \hline
    \end{tabular}
    \caption{Eigenvalues for Discrete Time 6th Order Systems}
    \label{tab:sys6deig}
\end{table}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{input2h.eps}
    \caption{Input of 6th Order System}
    \label{fig:input2h}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{output2h.eps}
    \caption{Output of 6th Order System}
    \label{fig:output2h}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{bode2h.eps}
    \caption{Bode Plots of 6th Order System}
    \label{fig:bode2h}
\end{figure}

\section{Time varying systems}

% 3i
\subsection{Determination of system order}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{svd3i.eps}
    \caption{Singular Values of Time Varying System}
    \label{fig:svd3i}
\end{figure}
\begin{table}
    \centering
    \begin{tabular}{|l|r|}
        \hline
        $i$ & $ |\ln \sigma_i - \ln \sigma_{i + 1}|$ \\
        \hline
        $ 1 $ & $ 0.8587 $ \\
        $ 2 $ & $ 2.3992 $ \\
        $ 3 $ & $ 0.6530 $ \\
        $ 4 $ & $ 0.2108 $ \\
        $ 5 $ & $ 0.4087 $ \\
        $ 6 $ & $ 0.3631 $ \\
        $ 7 $ & $ 0.0994 $ \\
        $ 8 $ & $ 0.1510 $ \\
        $ 9 $ & $ 1.1882 $ \\
        \hline
    \end{tabular}
    \caption{Differnce in log of singular values}
    \label{tab:svdiff}
\end{table}
The singular values of a time varying system with $s = 10$ are shown in
\autoref{fig:svd3i}. The difference of the logarithm of the singular values is
computed in \autoref{tab:svdiff}. We see two large gaps in singular values, one
between $\sigma_2$ and $\sigma_3$, and the other between $\sigma_9$ and
$\sigma_{10}$ when looking at the values on a log scale. As the difference is
larger between $\sigma_2$ and $\sigma_3$ and we have some prior knowledge of
the human wrist system, it is more likely that the order of the system is 2
instead of 9.

% 3j
\subsection{Moving VAF}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{vaf3j.eps}
    \caption{Input, Output, and VAF of Time Varying System}
    \label{fig:vaf3j}
\end{figure}
The moving VAF for the identified system with input $uk$ is plotted as $yi$ in
subplot 3 of \autoref{fig:vaf3j}. We see that the VAF changes over time and
that there are periods with very low VAF.

% 3k
\subsection{Use of EMG signals for estimation}
The input torque $uk$ and EMG signals $ek1$, $ek2$, $ek3$ are shown in the
first subplot of \autoref{fig:vaf3j}. The measured wrist rotations $yk$, as
well as two outputs from identified systems $yi1$, $yi2$ are shown in the
second subplot. The first identified system output $yi1$ is obtained from the
system after performing identification with input $uk$. The second identified
system output $yi2$ is obtained from after performing identification with input
$\begin{bmatrix} uk & ek1 & ek2 & ek3 \end{bmatrix}$. The moving VAF is
calculated for both identified systems and plotted in the third subplot. We see
that including the EMG signals in the input have little effect on either the
output of the identified system or the moving VAF.

% 3l
\subsection{Use of EMG signals for LPV estimation}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{vaf3l.eps}
    \caption{VAF for LPV System}
    \label{fig:vaf3l}
\end{figure}
As we are working with a time varying system, a Linear Parameter Varying (LPV)
apporach may provide a better estimate of the system. We redefine the system
difference equations to be:
\begin{align}
    x_{k + 1} &= \sum_{i = 1}^m \mu_k^{(i)} (A^{(i)} x_k + B^{(i)} u_k) \\
    y_k &= C x_k + D u_k
\end{align}
where $\mu_k^{(i)}$ is the $i$th scheduling variable.

Using the different EMG signals as scheduling variables, the moving VAF is
recomputed and plotted \autoref{fig:vaf3l}. We see that using an LPV structure
with signal $ek2$ results in higher VAF values than assuming an LTI structure
for the system, implying that the $ek2$ signal is related to the task
performed.

% 3m
\subsection{Use of multiple EMG signals for LPV estimation}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{mesh3m.eps}
    \caption{Magnitude for LPV $A$ matrix}
    \label{fig:mesh3m}
\end{figure}
All three EMG signals can be used as scheduling variables. \autoref{fig:mesh3m}
shows the computed LPV $A$ matrix, where x indices $1, 2$ correspond with the
LTI component of the systems. Indices $3, 4$ correspond to the $A$ matrix
associated with EMG signal $ek1$, $5, 6$ with $ek2$, and $7, 8$ with $ek3$. As
the $A$ matrices associated with $ek1$ and $ek3$ are small relative to the
others, they have little effect on the system and only EMG signal $ek2$ is
useful in system estimation.

% 3n
\subsection{Effect of EMG signal on system stiffness}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{frf3n.eps}
    \caption{Frequency Response with EMG Scheduling Variable}
    \label{fig:frf3j}
\end{figure}
The system frequency response is plotted in \autoref{fig:frf3j} for different
values of scheduling variable EMG signal 2. Given a standard MBK system, the
peak seen in subplot 1 of \autoref{fig:frf3j} is the natural frequency
$\omega_n$ of the system and is related to stiffness $k$ by
\autoref{eq:natfreq}. With the human wrist system, we take the mass $m$ to be
constant. As scheduling variable $ek2$ increases, $\omega_n$ decreases and
stiffness $k$ decreases.

\end{document}
