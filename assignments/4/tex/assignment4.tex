\documentclass[11pt,a4paper]{article}
% See geometry.pdf to learn the layout options. There are lots.
\usepackage{geometry}
\geometry{left = 3cm, right = 3cm, top = 3cm, bottom = 3cm}
% Activate to begin paragraphs with an empty line rather than an indent
\usepackage[parfill]{parskip}
\usepackage[table]{xcolor}
\usepackage{courier,multirow,fancyhdr}
\usepackage{float,amsmath,graphicx,framed,subfiles}
\usepackage{amssymb,subcaption,textcomp,listings}
\usepackage{booktabs,epstopdf,caption,units,rotating}
\usepackage[framed,numbered]{matlab-prettifier}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
% hyperref should be loaded last
\usepackage[
    colorlinks=true,
    pdfencoding=auto,
    pdfauthor={Oliver Lee},
    pdftitle={WB2301-5 System Identification and Parameter Estimation:
    Assignment 4 - Optimization & Real Data Analysis},
    pdftex
]{hyperref}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\mcode}[1]{
    \lstinline[
        style=Matlab-editor,
        basicstyle=\mlttfamily,
    ]{#1}
}

\frenchspacing

\pagestyle{fancy}
\fancyhead{}
\fancyhead[R]{Lee}
\fancyhead[L]{Assignment 4}


\title{WB2301-5 System Identification and Parameter Estimation \\
Assignment 4 - Optimization \& Real Data Analysis}
\author{Oliver Lee}
\date{\today}
\graphicspath{ {images/} }

\begin{document}
\maketitle

\section{Optimization Techniques}

% 1a
\subsection{Optimization with Grid and Gradient Search}
Using a model $ \hat{y}(t) $ assumed to be:
\begin{equation*}
    \hat{y}(t) = a\cos(\frac{bt}{2}) + b\sin(\frac{at}{2})
\end{equation*}
and parameters $ a,\: b \in [0, 10] $. To find the optimal values of $a$ and
$b$, the error function $e$ to minimize is defined as:
\begin{equation*}
    e = (y(t) - \hat{y}(t))^T (y(t) - \hat{y}(t))
\end{equation*}
where $y(t),\: \hat{y}(t) \in \mathbb{R}^{n \times 1} $ and $n$ is the number
of elements of the considered time vector.

\autoref{fig:optsurf} shows the error calculation for parameters $a, b$ with a
resolution of $0.1$ (a 2-d grid) as well as multiple pathways from the use of
gradient search with different initial conditions. All initial conditions are
chosen randomly with a uniform distribution from the search space, except for
the given condition $a = 5, \: b = 5$. As can be seen, poor choices in initial
conditions result in convergence at local minima not equal to the global
minimum. In fact, for the given problem and the randomly chosen initial
conditions, most do not converge at the global minimum.  If the error function
surface (or hypersurface for a general optimization problem) is not known a
priori (i.e. grid search was not performed before use of gradient search), it
is possible to execute a number of gradient searches which only return a local
minimum without knowing that the global minimum exists elsewhere in the search
space.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{optsurf.eps}
    \caption{Error Function Surface with Gradient Search Pathways}
    \label{fig:optsurf}
\end{figure}

% 1b
\subsection{Advantages and Disadvantages of Various Optimization Techniques}
\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|}
        \hline
%        \multicolumn{5}{|c|}{Performance of Optimization Techniques} \\
%        \hline
        \nonumber & \shortstack[c]{estimated\\parameters (a, b)} &
            \shortstack[c]{error\\residual} &
            \shortstack[c]{number of\\iterations} &
            \shortstack[c]{calculation\\time [s]} \\
        \hline
        Grid Search & $ (5.8,\: 3.5) $ & $ 8.4835 $ & $ 10201 $ &
            $ 0.9455 $ \\
        Gradient Search & $ (5.97,\: 3.53) $ & $ 5.3066 \times 10^{-17} $ &
            $ 8 $ & $ 0.6253 $ \\
        Genetic Algorithm & $ (5.97,\: 3.53) $ & $ 2.2417 \times 10^{-7} $ &
            $ 100 $ & $ 4.4695 $ \\
        \hline
    \end{tabular}
    \caption{Performance of Optimization Techniques}
    \label{tab:optperf}
\end{table}
In \autoref{tab:optperf} gradient search uses an initial condition of $ (5,\:
5) $. Performance of gradient search with different initial conditions will
result in small variations of estimated parameters, error residual, number of
iterations, and calculation time unless the initial condition is poorly choosen
and the search finds a different local minimum. Perfomance in the genetic
algorithm (GA) will also vary slightly in difference instances due to
randomness associated with genetic operations although the perfomance values
can be expected to be of the same order. Refer to \autoref{fig:optsurf} for
examples of poorly chosen initial conditions resulting in a different local
minimum with gradient search. \autoref{tab:optperf} shows that grid search
results in a large number of searches and does find the global minimum,
although the precision of the estimated parameters is limited by the resolution
of the grid used. Both gradient search and the genetic algorithm find the same
minimum, with higher precision. Gradient search is able to do quickly, with
fewest function iterations and lowest computation time. The GA is also able to
find the global minimum is fewer function iterations than grid search (orders
of magnitude lower) but total computation time is higher due to creation of
candidate solutions and selection/genetic operations used in creating
subsequent generations. Note that the number of iterations for GA is the number
of generations; the number of function evaluations is equal to product of
number of iterations and population size. For this problem, the population size
is $50$ giving a total number of function evaluations of $5000$. Although the
GA optimization takes longer in this
problem, larger and more complex optimization problems may have jacobian and
hessian matrices that are more expensive to compute (in time and memory) for
gradient based methods and GA may faster in some cases.

Advantages and disadvantages for the three optimization techniques can be
summarized below:
\begin{itemize}
    \item Grid Search
        \begin{itemize}
            \item Will determine global minimum (with given grid resolution)
            \item Astronomical number of function evalutaions (dependent on
                grid resolution)
        \end{itemize}
    \item Gradient Search
        \begin{itemize}
            \item Very fast convergence near optimum
            \item Dependent on initial conditions
        \end{itemize}
    \item Genetic Algorithm
        \begin{itemize}
            \item Does not need to compute function gradients
            \item Slow convergence near optimum
        \end{itemize}
\end{itemize}

% 1c
\subsection{``Improvements'' for Grid Search}
The estimate for grid search can be improved by increasing the resolution of
the search grid, that is, increasing the resolution for the candidate solutions
of $a$ and $b$. While this is simple to implement, a 10x increase in resolution
for both $a$ and $b$ increases the number of function evaluations by a factor
of 100. This is expensive computationally, although grid search is easily
parallelized and may be a feasible solution if resources are available.

% 1d
\subsection{Options of Genetic Algorithms}
Genetic Algorithms have a number of options that affect performance of
optimization.
\begin{itemize}
    \item\mcode{PopulationSize}- Size of the population. A population size
        that is too large can result in slow convergence due to computational
        cost associated with large amounts of data. A size that is too small
        can also result in slow convergence due to limited search range as a
        result of too few genetic samples. If elitist selection and converge is
        poorly tuned, a small population size can also result in premature
        convergence.
    \item\mcode{EliteCount}- The positive integer specifying how many
        individuals survive in the next generation. With zero parent solutions
        surviving in subsequent generations, there may be a loss of good
        solutions. With too many, the ability to search the rest of the
        parameter space is reduced resulting more generations necessary for
        convergence or convergence in a local minimum.
    \item\mcode{CrossoverFraction}- The fraction of the population of
        subsequent generations created by crossover of parent solutions from
        the previous generation. A fraction that is too large can lead to
        premature convergence; the amount of children selected from mutation
        will not be large enough to explore other areas of the parameter space
        before convergence in a local minimum due to crossover/elitist
        selection. A fraction that is too small can lead to low genetic
        variation, resulting to slow convergence as a result of high mutation
        rate.
    \item\mcode{PopInitRange}- The range of parameter values for the initial
        population. A poorly formed initial range can result in an increase in
        generations required for convergence as more time is necessary to span
        the search space through crossover and mutation. If information
        regarding areas where optimal solutions exist, the PopInitRange can be
        formuated so that the initial population begins in those areas.
    \item\mcode{Generations}- The maximum number of iterations before the
        algorithm halts. If chosen too small, the algorithm may halt before
        convergence.  The algorithm stops wonce convergence is reached, however
        poor fomulation for convergence could lead to unnecessary and time
        consuming iterations.
\end{itemize}

% 1e
\subsection{Combination of Grid and Gradient Search}
Grid and gradient search can be combined to robustly by reducing the resolution
of grid search and using each point as an initial condition for gradient
search. As gradient search has fast convergence, the increase in function
evaluations due to gradient search is smaller than the decrease in function
evaluations due to the reduction in grid resolution. With the number of
iterations of each gradient search on the order of 10 and the decrease of
resolution by 10 for each $a$ and $b$, the number of function evaluations of
the combined search is an order of magnitude smaller than grid search alone.

Using the search function decribed in \autoref{lst:combsearch} to optimize
parameters $a$ and $b$, we find the performance metrics as described in
\autoref{tab:combperf}. The pathways of the gradient searches are shown in
\autoref{fig:combsearch} using a resolution of $1$ for $a$ and $b$ for the grid
resolution. While the global minimum is found, we can see visually that some of
the pathways converge at local minima and not the global minimum and show the
sensitivity of gradient search to the initial condition. While total
computation time is quite large compared to both grid search and a single
instance of gradient search (see \autoref{tab:optperf}), it is comparable to
GA. Number of iterations is the sum of the gradient search iterations for all
initial conditions and is equal to the total number of function evaluations. As
expected, the number of iterations is an order of magnitude less than simple
grid search. The parameter estimates match the values for gradient search (with
a good initial condition) and GA.

\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|}
        \hline
%        \multicolumn{5}{|c|}{Performance of Optimization Techniques} \\
%        \hline
        \nonumber & \shortstack[c]{estimated\\parameters (a, b)} &
            \shortstack[c]{error\\residual} &
            \shortstack[c]{number of\\iterations} &
            \shortstack[c]{calculation\\time [s]} \\
        \hline
        Combined Search & $ (5.97,\: 3.53) $ & $ 1.8310 \times 10^{-28} $ &
            $ 1948 $ & $ 4.2724 $ \\
        \hline
    \end{tabular}
    \caption{Performance of Combined Grid and Gradient Search}
    \label{tab:combperf}
\end{table}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{combsearch.eps}
    \caption{Gradient Search Pathways from Combined Search}
    \label{fig:combsearch}
\end{figure}

\newpage
\lstset{
    caption=Combined Grid and Gradient Search Function,
    captionpos=b,
    label={lst:combsearch},
}
\lstinputlisting[
    style=Matlab-editor,
    basicstyle=\footnotesize\mlttfamily,
]{../combinedsearch.m}

\section{Real Data Analysis}

% 2a
\subsection{Perturbation and System Response Data}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{wristdata.eps}
    \caption{Angle Perturbation Input and Wrist Output Torque}
    \label{fig:wristdata}
\end{figure}
As stated in the question description, the experiment measures the wrist torque
of a human when subjected to small angle perturbations about a neutral
position. The input and output data are presented in \autoref{fig:wristdata}.

% 2b
\subsection{Coherence of Whole Dataset}
Reasons that the coherence of the whole dataset decreases compared to
individual segments are:
\begin{itemize}
    \item \textbf{Nonlinearity of the system} - The system is nonlinear. Since
        each segment uses only small angle perturbations about a given point,
        we can approximate behavior with a linear system for each segment. For
        small enough changes about an operating point of a system, the first
        order term of the Taylor expansion of the system will dominate. This
        process is known as \textbf{linearization} and is commonly used to
        analyze the behavior of a nonlinear system about a given point.
        However, if we combine all segments and analyze the whole data,
        coherence will decrease as each individual segment was about different
        operating points and the data can be viewed as the combination of
        different linear systems.
    \item \textbf{Time variance of the system} - A human response can be viewed
        as a time variant system as humans are subject to things such as
        fatigue, boredom, etc, and cannot be expected to react in an identical
        fashion to stimuli over the course of a long experiment. Thus if the
        system varies over the course of the different segments, which result
        in poor coherence.
\end{itemize}

% 2c
\subsection{Validity of LTI identification}
If there are indications that the system and nonlinear and time varying, than
application of linear time invariant identification techniques will result in
poor system identification.

% 2d
\subsection{Dynamic Characteristics and Parameter Estimation}
A mass, spring, damper system is represented by the second-order transfer
function:
\begin{equation*}
    H(s) = \frac{1}{Ms^2 + Bs + K}
\end{equation*}
where $M$ is the mass, $B$ is the damping coefficient, and $K$ is the spring
constant. At low frequencies, the $K$ term dominates the other terms in the
denominator of the system transfer function, and the spring parameter can be
estimated by comparing the frequency response to $1/K$. At high frequencies,
the $Ms^2$ term in the denominator dominates, and the magnitude of the
frequency response can be used to estimate the mass. Frequencies in between the
high and low ranges can be used to determine to the damping parameter $B$ after
estimating $M$ and $K$.

% 2e
\subsection{Estimation of Mass, Spring, Damper Parameters}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{mckfrf.eps}
    \caption{Frequency Response and Coherence for Wrist Data in Perturbed
        Frequency Range}
    \label{fig:mckfrf}
\end{figure}
The estimated mass, spring, and damper parameters do not match well in both the
gain and phase plots in the perturbed frequency range ($2$ and $20$ Hz) and are
shown in \autoref{fig:mckfrf}. The dotted lines with markers display the
frequency response of the measured data and dashed lines display the frequency
response of the mass-spring-damper system using estimated parameters. Segments
are shown in \autoref{fig:wristdata} by vertical bars and the different
segments can be identified by the plotted color.

% 2f
\subsection{Parameter Estimation with Frequency and Coherence Weighting}
Limiting to the error function to the range of perturbed frequencies ($2$ -
$20$ Hz) and by using frequency and coherence weighing in the error function
for parameter estimation results in a better parameter estimates; the improved
model has a better fit with the measured data. The frequency response of the
model with improved estimates is displayed in \autoref{fig:mckfrf}. Comparison
of the error residual between the models and measured data is presented in
\autoref{tab:mckerr}, and uses the sum of squares of the frequency and
coherence weighted error for perturbed frequencies to compare the fit of the
two parameter estimates.

\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|}
        \hline
        \nonumber & segment 1 & segment 2 & segment 3 & segment 4 \\
        \hline
        initial estimate & $15.6188$ & $34.1516$ & $22.9896$ & $28.6137$ \\
        improved estimate & $0.4966$ & $0.4267$ & $0.3800$ & $0.3365$ \\
        \hline
    \end{tabular}
    \caption{Unweighted Error Residual of Parameter Estimates for Wrist Data}
    \label{tab:mckerr}
\end{table}

% 2g
\subsection{Derivation of Transfer Function with Velocity Feedback}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{clvelfb.png}
    \caption{Human Wrist System with Velocity Feedback}
    \label{fig:clsys}
\end{figure}
Using the block diagram of the system with velocity feedback, as shown in
\autoref{fig:clsys}, we can derive the transfer function of the closed loop
system. Starting with definitions of intermediate signals $Y(s)$, $E_1(s)$, and
$E_2(s)$:
\begin{equation*}
    Y(s) = \frac{1}{Ms}E(s) \qquad E_1(s) = BY(s) + E_2(s) \qquad
    E_2(s) = K_v e^{-t_d s} H_{act} Y(s) + KX(s)
\end{equation*}
Although not shown explictly in \autoref{fig:clsys}, the delay block is given
by transfer function $ e^{-t_d s} $, where $t_d$ is the specified delay. We can
then write an expression for $E(s)$:
\begin{align*}
    E(s) &= T(s) - E_1(s) = T(s) - (BY(s) + E_2(s)) \\
         &= T(s) - (BY(s) + K_v e^{-t_d s} H_{act} Y(s) + KX(s)) \\
         &= T(s) - (B + K_v e^{-t_d s} H_{act}) Y(s) - KX(s)
\end{align*}
Substituting the relation betwen $E(s)$ and $Y(s)$, we have:
\begin{align*}
    Ms Y(s) &= T(s) - (B + K_v e^{-t_d s} H_{act}) Y(s) - KX(s) \\
    (Ms + B + K_v e^{-t_d s} H_{act}) Y(s) &= T(s) - KX(s)
\end{align*}
From the block diagram, we relate $Y(s)$ to $X(s)$ by:
\begin{equation*}
    X(s) = \frac{1}{s} Y(s)
\end{equation*}
Replacing $Y(s)$ in the expression of the closed loop system:
\begin{equation*}
    (Ms + B + K_v e^{-t_d s} H_{act}) s X(s) = T(s) - KX(s)
\end{equation*}
The resultant transfer function is:
\begin{equation*}
    \frac{X(s)}{T(s)} = \frac{1}{Ms^2 + (B + K_v e^{-t_d s} H_{act}) s  + K}
\end{equation*}

% 2h
\subsection{Parameter Estimation of Transfer Function with Velocity Feedback}
Plots of the improved 3 parameter estimate $(M, B, K)$ and 6 parameter estimate
$(M, B, K, K_v, t_d, w)$ are shown in \autoref{fig:6parfrf}. The improved 3
parameter estimate is plotted as a dashed line and the 6 parameter estimate
which includes feedback gain $K_v$ and time delay $t_d$ of velocity feedback
and cut-off frequency $w$ of the activation filter in addition to the $M$, $B$,
$K$ parameters of the improved estimate. Coherence is not shown as it is the
same as \autoref{fig:mckfrf}. A table of the error residual between the models
and measured data is presented in \autoref{tab:6parerr}, and again uses the sum
of squares and of the frequency and coherence weighted error in the range of
perturbed frequencies for calculation of the error residual. Fit of the 6
parameter model is improved, although to less of an extent when implementing
frequency and coherence weighting in the error function.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{6parfrf.eps}
    \caption{Frequency Response and Coherence for Wrist Data in Perturbed
        Frequency Range for Different Parameter Vectors}
    \label{fig:6parfrf}
\end{figure}

\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|}
        \hline
        \nonumber & segment 1 & segment 2 & segment 3 & segment 4 \\
        \hline
        3 param. est. $(M, B, K)$ &
            $0.4966$ & $0.4267$ & $0.3800$ & $0.3365$ \\
        6 param. est. $(M, B, K, K_v, t_d, w)$ &
            $0.1091$ & $0.1272$ & $0.1171$ & $0.0873$ \\
        \hline
    \end{tabular}
    \caption{Unweighted Error Residual of Different Parameter Vector Estimates
        for Wrist Data}
    \label{tab:6parerr}
\end{table}

% 2i
\subsection{SEM of Estimated Parameters}
\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|}
        \hline
        \nonumber & segment 1 & segment 2 & segment 3 & segment 4 \\
        \hline
        $\unit[M]{[kg\,m^2]}$ & $0.0027$ & $0.0027$ & $0.0026$ & $0.0026$ \\
        $\unit[B]{[\frac{kg\,m^2}{s\,rad}]}$ & $0.0508$ & $0.0489$ &
            $0.0595$ & $0.0583$ \\
        $\unit[K]{[N\,m/rad]}$ & $4.2514$ & $4.7312$ & $6.1855$ & $7.5809$ \\
        $\unit[K_v]{[rad/s]}$ & $-0.0355$ & $-0.0467$ &
            $-0.0477$ & $-0.0671$ \\
        $\unit[t_d]{[s]}$ & $0.0600$ & $0.0540$ & $0.0601$ & $0.0543$ \\
        $\unit[w]{[rad/s]}$ & $35.8176$ & $27.4777$ & $28.0485$ & $25.6516$ \\
        \hline
    \end{tabular}
    \caption{Estimated Parameters from Wrist with Velocity Feedback Model}
    \label{tab:segparam}
\end{table}

\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|}
        \hline
        \nonumber & segment 1 & segment 2 & segment 3 & segment 4 \\
        \hline
        $\unit[M]{[kg\,m^2]}$ & $0.0001$ & $0.0001$ & $0.0001$ & $0.0000$ \\
        $\unit[B]{[\frac{kg\,m^2}{s\,rad}]}$ & $0.0025$ & $0.0025$ &
            $0.0023$ & $0.0019$ \\
        $\unit[K]{[N\,m/rad]}$ & $0.0972$ & $0.1192$ & $0.1316$ & $0.1171$ \\
        $\unit[K_v]{[rad/s]}$ & $0.0056$ & $0.0089$ & $0.0100$ & $0.0110$ \\
        $\unit[t_d]{[s]}$ & $0.0057$ & $0.0059$ & $0.0062$ & $0.0037$ \\
        $\unit[w]{[rad/s]}$ & $4.6994$ & $3.5391$ & $4.0074$ & $2.6950$ \\
        \hline
    \end{tabular}
    \caption{SEM of Estimated Parameters from Wrist with Velocity Feedback
        Model}
    \label{tab:segsem}
\end{table}

A table with the Standard Error of the Mean (SEM) of each estimated parameter
using the model which includes velocity feedback is given in
\autoref{tab:segsem}.  Precision is given up to 4 places after the decimal in
the SEM values. In order to evaluate the fit of the parameter estimates, we
compare the SEM to the estimated value and plot a ``normalized'' SEM  which is
defined as:
\begin{equation*}
    normalized \: SEM = \frac{SEM}{|estimated \: parameter|}
\end{equation*}
and is plotted in \autoref{fig:segnormsem}. Note that the dotted lines in this
plot do not represent any relation between the parameters and are only used so
that the normalized SEM values for a single segment can be easily identified.
We can see that the velocity feedback gain $K_v$ is least accurately estimated
parameter and that mass $M$, damping constant $B$, and spring constant $K$ are
fit well to the measured data. The estimated parameters values used in the SEM
normalization are given in \autoref{tab:segparam}. Note that the units
displayed \autoref{tab:segparam} and \autoref{tab:segsem} use the units for a
torsional spring equation since the experiment deals with rotations and not
linear displacements.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{segnormsem.eps}
    \caption{Normalized SEM for Estimated Parameters}
    \label{fig:segnormsem}
\end{figure}


% 2j
\subsection{Parameters Dependent on Background Torque}
From \autoref{fig:wristdata}, the mean torque magnitude increases with each
segment. The estimated parameter values for each segment are shown in
\autoref{tab:segparam}. We can see that spring constant $K$ increases each
segment (or equivalently, as torque magnitude increases). We expect that $K$
increases with increasing torque; if the user is instructed to maintain a
larger torque value, the amount of torque exerted given the same angle
perturbation must be higher. Larger torques result in larger accelerations of
the wrist, resulting in larger wrist velocities. For damping constant $B$, it
is hard determine if it changes with torque given the measured data. We see
little change in in mass $M$ and time delay $t_d$. As the mass of the system is
not changing, nor the reation time of the human subject (at least not
significantly over the course of the experiment), we expect these parameters to
remain constant over all segments. As velocity feedback $K_v$ and activation
cut-off frequency $w$ have the highest normalized SEM values, it is hard to
determine how these parameters change with background torque with the measured
data.

% 2k
\subsection{VAF of Segments}
The Variance Account For (VAF) for each segment is given in
\autoref{tab:segvaf}.
The measured and estimated rotation using a model with
parameters from \autoref{tab:segparam} are displayed in \autoref{fig:segrot}.
Zooming in on short time segments ($2$ seconds) in \autoref{fig:segrotzoom}
shows a good fit on signal shape although the magnitude differs by a small
amount, which matches with the calculated VAF values. Segments 1 and 2 appear
to have a non-zero offset between the measured and estimated rotations.
Measured input and output data were detrended before calculation of VAF and
plotting. TODO: review this section.
\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|}
        \hline
        \nonumber & segment 1 & segment 2 & segment 3 & segment 4 \\
        \hline
        VAF & $81.9681$ & $87.0021$ & $92.3029$ & $90.4893$ \\
        \hline
    \end{tabular}
    \caption{VAF for Wrist with Velocity Feedback Model}
    \label{tab:segvaf}
\end{table}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{segrot.eps}
    \caption{Estimated and Measured Wrist Rotation}
    \label{fig:segrot}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{segrotzoom.eps}
    \caption{Zoomed Estimated and Measured Wrist Rotation}
    \label{fig:segrotzoom}
\end{figure}

% 2l
\subsection{Use of High-Pass Filters}
Due to temperature effects, we expect low frequency drift in the torque signal.
Without using a high-pass filter, the optimization would try and fit the model
parameters to this drift. However, we know this drift effect to be independent
of the wrist model and would result in poorer parameter estimates.

% 2m
\subsection{Estimation of Parameters in Time Domain}
Simulating the model in the time domain and using the difference in the
measured and simulated output as the error results, we obtain the estimated
parameters listed in \autoref{tab:segparamhp} in the time domain columns.
Note that the signal is high-pass filtered for time domain optimization and the
parameters estimated with frequency domain optimization match the values from
\autoref{tab:segparam}.

% 2n
\subsection{Comparison of Frequency and Time Domain Estimates}
SEM and VAF are computed using time domain optmization and values for each
parameter are presented in the time domain columns of \autoref{tab:segsemhp}
and \autoref{tab:segvafhp}. While the SEM and VAF were previously calculated
using frequency domain optimization and are shown in \autoref{tab:segsem} and
\autoref{tab:segvaf} respectively, the VAF calculations have been recomputed
using high-pass filtered data in \autoref{tab:segvafhp}. While most of the SEM
values are lower in time domain optimization, the VAF values are high for each
segment after high-pass filtering is used. This may be a result of the
different error functions used in the time domain and frequency domain. A plot
of the normalized SEM values for parameter estimates in time domain and
frequency domain are is shown in \autoref{fig:segnormsemtf}. From the plot, we
can see that time domain results in better parameter estimates in terms of
normalized SEM.

\begin{sidewaystable}
    \centering
    \begin{tabular}{|l|r|r|r|r|r|r|r|r|}
        \hline
        \nonumber &
            \multicolumn{2}{c|}{segment 1} &
            \multicolumn{2}{c|}{segment 2} &
            \multicolumn{2}{c|}{segment 3} &
            \multicolumn{2}{c|}{segment 4} \\
        \hline
        \nonumber &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} \\
        \hline
        $\unit[M]{[kg\,m^2]}$ &
            $0.0030$ & $0.0027$ & $0.0029$ & $0.0027$ &
            $0.0026$ & $0.0026$ & $0.0023$ & $0.0026$ \\
        $\unit[B]{[\frac{kg\,m^2}{s\,rad}]}$ &
            $0.0371$ & $0.0508$ & $0.0408$ & $0.0489$ &
            $0.0595$ & $0.0595$ & $0.0670$ & $0.0583$ \\
        $\unit[K]{[N\,m/rad]}$ &
            $4.9675$ & $4.2514$ & $5.3029$ & $5.7312$ &
            $6.1462$ & $6.1855$ & $6.5311$ & $7.5809$ \\
        $\unit[K_v]{[rad/s]}$ &
            $-0.0782$ & $-0.0355$ & $-0.0775$ & $-0.0467$ &
            $-0.0659$ & $-0.0477$ & $-0.0660$ & $-0.0671$ \\
        $\unit[t_d]{[s]}$ &
            $0.0400$ & $0.0600$ & $0.0398$ & $0.0540$ &
            $0.0471$ & $0.0601$ & $0.0507$ & $0.0543$ \\
        $\unit[w]{[rad/s]}$ &
            $28.3671$ & $35.8176$ & $28.8176$ & $27.4777$ &
            $23.1918$ & $28.0485$ & $19.4152$ & $25.6516$ \\
        \hline
    \end{tabular}
    \caption{Estimated Parameters from Wrist with Velocity Feedback Model and
        High Pass Filtering for Time and Frequency Domain Optimization}
    \label{tab:segparamhp}
\end{sidewaystable}

\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|r|r|r|r|}
        \hline
        \nonumber &
            \multicolumn{2}{c|}{segment 1} &
            \multicolumn{2}{c|}{segment 2} &
            \multicolumn{2}{c|}{segment 3} &
            \multicolumn{2}{c|}{segment 4} \\
        \hline
        \nonumber &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} \\
        \hline
        $\unit[M]{[kg\,m^2]}$ &
            $0.0000$ & $0.0001$ & $0.0000$ & $0.0001$ &
            $0.0001$ & $0.0001$ & $0.0001$ & $0.0000$ \\
        $\unit[B]{[\frac{kg\,m^2}{s\,rad}]}$ &
            $0.0005$ & $0.0025$ & $0.0005$ & $0.0025$ &
            $0.0006$ & $0.0023$ & $0.0007$ & $0.0019$ \\
        $\unit[K]{[N\,m/rad]}$ &
            $0.0123$ & $0.0972$ & $0.0110$ & $0.1192$ &
            $0.0165$ & $0.1316$ & $0.0188$ & $0.1171$ \\
        $\unit[K_v]{[rad/s]}$ &
            $0.0011$ & $0.0056$ & $0.0012$ & $0.0089$ &
            $0.0029$ & $0.0100$ & $0.0041$ & $0.0110$ \\
        $\unit[t_d]{[s]}$ &
            $0.0004$ & $0.0057$ & $0.0004$ & $0.0059$ &
            $0.0007$ & $0.0062$ & $0.0011$ & $0.0037$ \\
        $\unit[w]{[rad/s]}$ &
            $0.2817$ & $4.6994$ & $0.2771$ & $3.5391$ &
            $0.4552$ & $4.0074$ & $0.6427$ & $2.6950$ \\
        \hline
    \end{tabular}
    \caption{SEM of Estimated Parameters from Wrist with Velocity Feedback
        Model and High Pass Filtering for Time and Frequency Domain
        Optimization}
    \label{tab:segsemhp}
\end{table}

\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|r|r|r|r|}
        \hline
        \nonumber &
            \multicolumn{2}{c|}{segment 1} &
            \multicolumn{2}{c|}{segment 2} &
            \multicolumn{2}{c|}{segment 3} &
            \multicolumn{2}{c|}{segment 4} \\
        \hline
        \nonumber &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} \\
        \hline
        VAF &
            $93.9951$ & $94.6912$ & $95.4617$ & $96.2253$ &
            $94.8857$ & $95.1913$ & $92.4736$ & $95.2300$ \\
        \hline
    \end{tabular}
    \caption{VAF for Wrist with Velocity Feedback Model and High Pass
        Filtering for Time and Frequency Domain Optimization}
    \label{tab:segvafhp}
\end{table}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{segnormsemtf.eps}
    \caption{Normalized SEM for Estimated Parameters in Time and Frequency
        Domain}
    \label{fig:segnormsemtf}
\end{figure}

% 2o
\subsection{High Frequency Noise in Time Domain Estimation}
High frequency noise has a lesser effect on parameter estimation in the time
domain. A least squares fit of the model parameters will minimize the error
residual between the simulated model and measured data. As we assume that noise
has zero mean and is uncorrelated to the input and output signals, the optimal
parameters will also minimize the effect of noise on the error residual.

% 2p
\subsection{Validation Using a Second Dataset}
Validation of model parameters should always be done with a dataset different
than the one used to estimate the parameters. Since the optimization procedure
will return parameters that minimize error, using the same dataset for
parameter estimation and validation can result in overfitting of model
parameters, or fitting the the data to biases or noise present in the data. Use
of a separate, independent data set for validation reduces problems of
overfitting and gives insight on how model will generalize to independent or
unknown datasets. Calculation of VAF for verification dataset shows shows
similar values to the training dataset and the values are given in
\autoref{tab:segvafver}.

\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|r|r|r|r|}
        \hline
        \nonumber &
            \multicolumn{2}{c|}{segment 1} &
            \multicolumn{2}{c|}{segment 2} &
            \multicolumn{2}{c|}{segment 3} &
            \multicolumn{2}{c|}{segment 4} \\
        \hline
        \nonumber &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} \\
        \hline
        VAF &
            $94.6432$ & $95.4684$ & $93.7491$ & $94.0920$ &
            $93.9296$ & $94.4241$ & $92.1357$ & $95.3843$ \\
        \hline
    \end{tabular}
    \caption{VAF for Wrist with Velocity Feedback Model and High Pass
        Filtering for Time and Frequency Domain Optimization on Validation
        Dataset}
    \label{tab:segvafver}
\end{table}

% 2q
\subsection{Advantages and Disadvantages of Time Domain Identification}
From the experimental data, time domain identification produces better
estimates of the model parameters. However, it requires simulation of the
system at each iteration which is much slower than frequency domain analysis.
Furthermore, frequency domain modeling uses transfer functions which represent
the input and output relation of linear time-invariant systems, resulting in
poor modeling of nonlinear systems.

\end{document}
