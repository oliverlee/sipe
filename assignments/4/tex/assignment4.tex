\documentclass[11pt,a4paper]{article}
% See geometry.pdf to learn the layout options. There are lots.
\usepackage{geometry}
\geometry{left = 3cm, right = 3cm, top = 3cm, bottom = 3cm}
% Activate to begin paragraphs with an empty line rather than an indent
\usepackage[parfill]{parskip}
\usepackage[table]{xcolor}
\usepackage{courier,multirow,fancyhdr}
\usepackage{float,amsmath,graphicx,framed,subfiles}
\usepackage{amssymb,subcaption,textcomp,listings}
\usepackage{booktabs,epstopdf,caption,units,rotating}
\usepackage[framed,numbered]{matlab-prettifier}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
% hyperref should be loaded last
\usepackage[
    colorlinks=true,
    pdfencoding=auto,
    pdfauthor={Oliver Lee},
    pdftitle={WB2301-5 System Identification and Parameter Estimation:
    Assignment 4 - Optimization & Real Data Analysis},
    pdftex
]{hyperref}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\mcode}[1]{
    \lstinline[
        style=Matlab-editor,
        basicstyle=\mlttfamily,
    ]{#1}
}

\frenchspacing

\pagestyle{fancy}
\fancyhead{}
\fancyhead[R]{Lee}
\fancyhead[L]{Assignment 4}


\title{WB2301-5 System Identification and Parameter Estimation \\
Assignment 4 - Optimization \& Real Data Analysis}
\author{Oliver Lee}
\date{\today}
\graphicspath{ {images/} }

\begin{document}
\maketitle

\section{Optimization Techniques}

% 1a
\subsection{Optimization with Grid and Gradient Search}
Using a model $ \hat{y}(t) $ assumed to be:
\begin{equation*}
    \hat{y}(t) = a\cos(\frac{bt}{2}) + b\sin(\frac{at}{2})
\end{equation*}
and parameters $ a,\: b \in [0, 10] $. To find the optimal values of $a$ and
$b$, the error function $e$ to minimize is defined as:
\begin{equation*}
    e = (y(t) - \hat{y}(t))^T (y(t) - \hat{y}(t))
\end{equation*}
where $y(t),\: \hat{y}(t) \in \mathbb{R}^{n \times 1} $ and $n$ is the number
of elements of the considered time vector.

\autoref{fig:optsurf} shows the error calculation for parameters $a, b$ with a
resolution of $0.1$ (a 2-d grid) as well as multiple pathways from the use of
gradient search with different initial conditions. All initial conditions are
chosen randomly with a uniform distribution from the search space, except for
the given condition $a = 5, \: b = 5$. As can be seen, poor choices in initial
conditions result in convergence at local minima not equal to the global
minimum. In fact, for the given problem and the randomly chosen initial
conditions, most do not converge at the global minimum.  If the error function
surface (or hypersurface for a general optimization problem) is not known a
priori (i.e. grid search was not performed before use of gradient search), it
is possible to execute a number of gradient searches which only return a local
minimum without knowing that the global minimum exists elsewhere in the search
space.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{optsurf.eps}
    \caption{Error Function Surface with Gradient Search Pathways}
    \label{fig:optsurf}
\end{figure}

% 1b
\subsection{Advantages and Disadvantages of Various Optimization Techniques}
\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|}
        \hline
%        \multicolumn{5}{|c|}{Performance of Optimization Techniques} \\
%        \hline
        \nonumber & \shortstack[c]{estimated\\parameters (a, b)} &
            \shortstack[c]{error\\residual} &
            \shortstack[c]{number of\\iterations} &
            \shortstack[c]{calculation\\time [s]} \\
        \hline
        Grid Search & $ (5.8,\: 3.5) $ & $ 8.4835 $ & $ 10201 $ &
            $ 0.9455 $ \\
        Gradient Search & $ (5.97,\: 3.53) $ & $ 5.3066 \times 10^{-17} $ &
            $ 8 $ & $ 0.6253 $ \\
        Genetic Algorithm & $ (5.97,\: 3.53) $ & $ 2.2417 \times 10^{-7} $ &
            $ 100 $ & $ 4.4695 $ \\
        \hline
    \end{tabular}
    \caption{Performance of Optimization Techniques}
    \label{tab:optperf}
\end{table}
In \autoref{tab:optperf} gradient search uses an initial condition of $ (5,\:
5) $. Performance of gradient search with different initial conditions will
result in small variations of estimated parameters, error residual, number of
iterations, and calculation time unless the initial condition is poorly choosen
and the search finds a different local minimum. Perfomance in the genetic
algorithm (GA) will also vary slightly in difference instances due to
randomness associated with genetic operations although the perfomance values
can be expected to be of the same order. Refer to \autoref{fig:optsurf} for
examples of poorly chosen initial conditions resulting in a different local
minimum with gradient search. \autoref{tab:optperf} shows that grid search
results in a large number of searches and does find the global minimum,
although the precision of the estimated parameters is limited by the resolution
of the grid used. Both gradient search and the genetic algorithm find the same
minimum, with higher precision. Gradient search is able to do quickly, with
fewest function iterations and lowest computation time. The GA is also able to
find the global minimum is fewer function iterations than grid search (orders
of magnitude lower) but total computation time is higher due to creation of
candidate solutions and selection/genetic operations used in creating
subsequent generations. Note that the number of iterations for GA is the number
of generations; the number of function evaluations is equal to product of
number of iterations and population size. For this problem, the population size
is $50$ giving a total number of function evaluations of $5000$. Although the
GA optimization takes longer in this
problem, larger and more complex optimization problems may have jacobian and
hessian matrices that are more expensive to compute (in time and memory) for
gradient based methods and GA may faster in some cases.

Advantages and disadvantages for the three optimization techniques can be
summarized below:
\begin{itemize}
    \item Grid Search
        \begin{itemize}
            \item Will determine global minimum (with given grid resolution)
            \item Astronomical number of function evalutaions (dependent on
                grid resolution)
        \end{itemize}
    \item Gradient Search
        \begin{itemize}
            \item Very fast convergence near optimum
            \item Dependent on initial conditions
        \end{itemize}
    \item Genetic Algorithm
        \begin{itemize}
            \item Does not need to compute function gradients
            \item Slow convergence near optimum
        \end{itemize}
\end{itemize}

% 1c
\subsection{``Improvements'' for Grid Search}
The estimate for grid search can be improved by increasing the resolution of
the search grid, that is, increasing the resolution for the candidate solutions
of $a$ and $b$. While this is simple to implement, a 10x increase in resolution
for both $a$ and $b$ increases the number of function evaluations by a factor
of 100. This is expensive computationally, although grid search is easily
parallelized and may be a feasible solution if resources are available.

% 1d
\subsection{Options of Genetic Algorithms}
Genetic Algorithms have a number of options that affect performance of
optimization.
\begin{itemize}
    \item\mcode{PopulationSize}- Size of the population. A population size
        that is too large can result in slow convergence due to computational
        cost associated with large amounts of data. A size that is too small
        can also result in slow convergence due to limited search range as a
        result of too few genetic samples. If elitist selection and converge is
        poorly tuned, a small population size can also result in premature
        convergence.
    \item\mcode{EliteCount}- The positive integer specifying how many
        individuals survive in the next generation. With zero parent solutions
        surviving in subsequent generations, there may be a loss of good
        solutions. With too many, the ability to search the rest of the
        parameter space is reduced resulting more generations necessary for
        convergence or convergence in a local minimum.
    \item\mcode{CrossoverFraction}- The fraction of the population of
        subsequent generations created by crossover of parent solutions from
        the previous generation. A fraction that is too large can lead to
        premature convergence; the amount of children selected from mutation
        will not be large enough to explore other areas of the parameter space
        before convergence in a local minimum due to crossover/elitist
        selection. A fraction that is too small can lead to low genetic
        variation, resulting to slow convergence as a result of high mutation
        rate.
    \item\mcode{PopInitRange}- The range of parameter values for the initial
        population. A poorly formed initial range can result in an increase in
        generations required for convergence as more time is necessary to span
        the search space through crossover and mutation. If information
        regarding areas where optimal solutions exist, the PopInitRange can be
        formulated so that the initial population begins in those areas.
    \item\mcode{Generations}- The maximum number of iterations before the
        algorithm halts. If chosen too small, the algorithm may halt before
        convergence.  The algorithm stops once convergence is reached, however
        poor fomulation for convergence could lead to unnecessary and time
        consuming iterations.
\end{itemize}

% 1e
\subsection{Combination of Grid and Gradient Search}
Grid and gradient search can be combined to robustly find the global minimum by
reducing the resolution of grid search and using each point as an initial
condition for gradient search. As gradient search has fast convergence, the
increase in function evaluations due to gradient search is smaller than the
decrease in function evaluations due to the reduction in grid resolution. With
the number of iterations of each gradient search on the order of 10 and the
decrease of resolution by 10 for each $a$ and $b$, the number of function
evaluations of the combined search is an order of magnitude smaller than grid
search alone.

Using the search function decribed in \autoref{lst:combsearch} to optimize
parameters $a$ and $b$, we find the performance metrics as described in
\autoref{tab:combperf}. The pathways of the gradient searches are shown in
\autoref{fig:combsearch} using a resolution of $1$ for $a$ and $b$ for the grid
resolution. While the global minimum is found, we can see visually that some of
the pathways converge at local minima and not the global minimum and show the
sensitivity of gradient search to the initial condition. While total
computation time is quite large compared to both grid search and a single
instance of gradient search (see \autoref{tab:optperf}), it is comparable to
GA. Number of iterations is the sum of the gradient search iterations for all
initial conditions and is equal to the total number of function evaluations. As
expected, the number of iterations is an order of magnitude less than simple
grid search. The parameter estimates match the values for gradient search (with
a good initial condition) and GA.

\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|}
        \hline
%        \multicolumn{5}{|c|}{Performance of Optimization Techniques} \\
%        \hline
        \nonumber & \shortstack[c]{estimated\\parameters (a, b)} &
            \shortstack[c]{error\\residual} &
            \shortstack[c]{number of\\iterations} &
            \shortstack[c]{calculation\\time [s]} \\
        \hline
        Combined Search & $ (5.97,\: 3.53) $ & $ 1.8310 \times 10^{-28} $ &
            $ 1948 $ & $ 4.2724 $ \\
        \hline
    \end{tabular}
    \caption{Performance of Combined Grid and Gradient Search}
    \label{tab:combperf}
\end{table}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{combsearch.eps}
    \caption{Gradient Search Pathways from Combined Search}
    \label{fig:combsearch}
\end{figure}

\newpage
\lstset{
    caption=Combined Grid and Gradient Search Function,
    captionpos=b,
    label={lst:combsearch},
}
\lstinputlisting[
    style=Matlab-editor,
    basicstyle=\footnotesize\mlttfamily,
]{../combinedsearch.m}

\section{Real Data Analysis}

% 2a
\subsection{Perturbation and System Response Data}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{wristdata.eps}
    \caption{Angle Perturbation Input and Wrist Output Torque}
    \label{fig:wristdata}
\end{figure}
As stated in the question description, the experiment measures the wrist torque
of a human when subjected to small angle perturbations about a neutral
position. The input and output data are presented in \autoref{fig:wristdata}.

% 2b
\subsection{Coherence of Whole Dataset}
Reasons that the coherence of the whole dataset decreases compared to
individual segments are:
\begin{itemize}
    \item \textbf{Nonlinearity of the system} - The system is nonlinear. Since
        each segment uses only small angle perturbations about a given point,
        we can approximate behavior with a linear system for each segment. For
        small enough changes about an operating point of a system, the first
        order term of the Taylor expansion of the system will dominate. This
        process is known as \textbf{linearization} and is commonly used to
        analyze the behavior of a nonlinear system about a given point.
        However, if we combine all segments and analyze the whole data,
        coherence will decrease as each individual segment was about different
        operating points and the data can be viewed as the combination of
        different linear systems.
    \item \textbf{Time variance of the system} - A human response can be viewed
        as a time variant system as humans are subject to things such as
        fatigue, boredom, etc, and cannot be expected to react in an identical
        fashion to stimuli over the course of a long experiment. The resulting
        time-varying system can then be represented as different time-invariant
        systems during each segment and analysis as a single time-invariant
        system will result in poor coherence.
\end{itemize}

% 2c
\subsection{Validity of LTI identification}
If there are indications that the system is nonlinear and time varying, than
application of linear time invariant identification techniques will result in
poor system identification.

% 2d
\subsection{Dynamic Characteristics and Parameter Estimation}
A mass, spring, damper system is represented by the second-order transfer
function:
\begin{equation*}
    H(s) = \frac{1}{Ms^2 + Bs + K}
\end{equation*}
where $M$ is the mass, $B$ is the damping coefficient, and $K$ is the spring
constant. At low frequencies, the $K$ term dominates the other terms in the
transfer function denominator and the spring parameter can be estimated by
comparing the frequency response to $1/K$. At high frequencies, the $Ms^2$ term
in the denominator dominates and the magnitude of the frequency response can be
used to estimate the mass. Frequencies in between the high and low ranges can
be used to determine to the damping parameter $B$ after estimating $M$ and $K$.

% 2e
\subsection{Estimation of Mass, Spring, Damper Parameters}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{mckfrf.eps}
    \caption{Frequency Response and Coherence for Wrist Data in Perturbed
        Frequency Range}
    \label{fig:mckfrf}
\end{figure}
The estimated mass, spring, and damper parameters do not match well in both the
gain and phase plots in the perturbed frequency range ($2$ and $20$ Hz) and are
shown in \autoref{fig:mckfrf}. The dotted lines with markers display the
frequency response of the measured data and dashed lines display the frequency
response of the mass-spring-damper system using estimated parameters. Segments
are shown in \autoref{fig:wristdata} by vertical bars and the different
segments can be identified by the plotted color.

% 2f
\subsection{Parameter Estimation with Frequency and Coherence Weighting}
Limiting the error function to the range of perturbed frequencies ($2$ -
$20$ Hz) and using frequency and coherence weighing in the error function
for parameter estimation results in better parameter estimates; the improved
model has a better fit with the measured data. The frequency response of the
model with improved estimates is displayed in \autoref{fig:mckfrf} and can be
identified by the plots with solid lines. Comparison of the error residual
between the models and measured data is presented in \autoref{tab:mckerr} and
uses the sum of squares of the frequency and coherence weighted error in the
perturbed frequency range to compare the fit of the two parameter estimates.

\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|}
        \hline
        \nonumber & segment 1 & segment 2 & segment 3 & segment 4 \\
        \hline
        initial estimate & $15.6188$ & $34.1516$ & $22.9896$ & $28.6137$ \\
        improved estimate & $0.4966$ & $0.4267$ & $0.3800$ & $0.3365$ \\
        \hline
    \end{tabular}
    \caption{Unweighted Error Residual of Parameter Estimates for Wrist Data}
    \label{tab:mckerr}
\end{table}

% 2g
\subsection{Derivation of Transfer Function with Velocity Feedback}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{clvelfb.png}
    \caption{Human Wrist System with Velocity Feedback}
    \label{fig:clsys}
\end{figure}
Using the block diagram of the system with velocity feedback, as shown in
\autoref{fig:clsys}, we can derive the transfer function of the closed loop
system. We define the following intermediate signals $Y(s)$, $E_1(s)$, and
$E_2(s)$ to be:
\begin{equation*}
    Y(s) = \frac{1}{Ms}E(s) \qquad E_1(s) = BY(s) + E_2(s) \qquad
    E_2(s) = K_v e^{-t_d s} H_{act} Y(s) + KX(s)
\end{equation*}
Although not shown explictly in \autoref{fig:clsys}, the delay block is given
by transfer function $ e^{-t_d s} $, where $t_d$ is the specified delay. We can
then write an expression for $E(s)$:
\begin{align*}
    E(s) &= T(s) - E_1(s) = T(s) - (BY(s) + E_2(s)) \\
         &= T(s) - (BY(s) + K_v e^{-t_d s} H_{act} Y(s) + KX(s)) \\
         &= T(s) - (B + K_v e^{-t_d s} H_{act}) Y(s) - KX(s)
\end{align*}
Substituting the relation betwen $E(s)$ and $Y(s)$, we have:
\begin{align*}
    Ms Y(s) &= T(s) - (B + K_v e^{-t_d s} H_{act}) Y(s) - KX(s) \\
    (Ms + B + K_v e^{-t_d s} H_{act}) Y(s) &= T(s) - KX(s)
\end{align*}
From the block diagram, we relate $Y(s)$ to $X(s)$ by:
\begin{equation*}
    X(s) = \frac{1}{s} Y(s)
\end{equation*}
Replacing $Y(s)$ in the expression of the closed loop system:
\begin{equation*}
    (Ms + B + K_v e^{-t_d s} H_{act}) s X(s) = T(s) - KX(s)
\end{equation*}
The resultant transfer function is:
\begin{equation*}
    \frac{X(s)}{T(s)} = \frac{1}{Ms^2 + (B + K_v e^{-t_d s} H_{act}) s  + K}
\end{equation*}

% 2h
\subsection{Parameter Estimation of Transfer Function with Velocity Feedback}
Plots of the improved 3 parameter estimate $(M, B, K)$ and 6 parameter estimate
$(M, B, K,\allowbreak K_v, t_d, w)$ are shown in \autoref{fig:6parfrf}. The
improved 3 parameter estimate is plotted as a dashed line and the 6 parameter
estimate as a solid line; in this figure, as in \autoref{fig:mckfrf}, the
better estimate is shown with a solid line. The additional parameters used in
the 6 parameter model are feedback gain $K_v$, time delay $t_d$ of velocity
feedback, and cut-off frequency $w$ of the activation filter. Coherence is not
shown as it is the same as \autoref{fig:mckfrf}. A table of the error residual
between the models and measured data is presented in \autoref{tab:6parerr} and
again uses the sum of squares and of the frequency and coherence weighted error
in the range of perturbed frequencies. Fit of the 6 parameter model is
improved, although to less of an extent in terms of reduced residual when
compared to implementation of frequency and coherence weighting in the error
function.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{6parfrf.eps}
    \caption{Frequency Response and Coherence for Wrist Data in Perturbed
        Frequency Range for Different Parameter Vectors}
    \label{fig:6parfrf}
\end{figure}

\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|}
        \hline
        \nonumber & segment 1 & segment 2 & segment 3 & segment 4 \\
        \hline
        3 param. est. $(M, B, K)$ &
            $0.4966$ & $0.4267$ & $0.3800$ & $0.3365$ \\
        6 param. est. $(M, B, K, K_v, t_d, w)$ &
            $0.1091$ & $0.1272$ & $0.1171$ & $0.0873$ \\
        \hline
    \end{tabular}
    \caption{Unweighted Error Residual of Different Parameter Vector Estimates
        for Wrist Data}
    \label{tab:6parerr}
\end{table}

% 2i
\subsection{SEM of Estimated Parameters}
\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|}
        \hline
        \nonumber & segment 1 & segment 2 & segment 3 & segment 4 \\
        \hline
        $\unit[M]{[kg\,m^2]}$ & $0.0027$ & $0.0027$ & $0.0026$ & $0.0026$ \\
        $\unit[B]{[\frac{kg\,m^2}{s\,rad}]}$ & $0.0508$ & $0.0489$ &
            $0.0595$ & $0.0583$ \\
        $\unit[K]{[N\,m/rad]}$ & $4.2514$ & $4.7312$ & $6.1855$ & $7.5809$ \\
        $\unit[K_v]{[rad/s]}$ & $-0.0355$ & $-0.0467$ &
            $-0.0477$ & $-0.0671$ \\
        $\unit[t_d]{[s]}$ & $0.0600$ & $0.0540$ & $0.0601$ & $0.0543$ \\
        $\unit[w]{[rad/s]}$ & $35.8176$ & $27.4777$ & $28.0485$ & $25.6516$ \\
        \hline
    \end{tabular}
    \caption{Estimated Parameters from Wrist with Velocity Feedback Model}
    \label{tab:segparam}
\end{table}

\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|}
        \hline
        \nonumber & segment 1 & segment 2 & segment 3 & segment 4 \\
        \hline
        $\unit[M]{[kg\,m^2]}$ & $0.0001$ & $0.0001$ & $0.0001$ & $0.0000$ \\
        $\unit[B]{[\frac{kg\,m^2}{s\,rad}]}$ & $0.0025$ & $0.0025$ &
            $0.0023$ & $0.0019$ \\
        $\unit[K]{[N\,m/rad]}$ & $0.0972$ & $0.1192$ & $0.1316$ & $0.1171$ \\
        $\unit[K_v]{[rad/s]}$ & $0.0056$ & $0.0089$ & $0.0100$ & $0.0110$ \\
        $\unit[t_d]{[s]}$ & $0.0057$ & $0.0059$ & $0.0062$ & $0.0037$ \\
        $\unit[w]{[rad/s]}$ & $4.6994$ & $3.5391$ & $4.0074$ & $2.6950$ \\
        \hline
    \end{tabular}
    \caption{SEM of Estimated Parameters from Wrist with Velocity Feedback
        Model}
    \label{tab:segsem}
\end{table}

A table with the Standard Error of the Mean (SEM) of each estimated parameter
using the 6 parameter model is given in \autoref{tab:segsem}. Precision is
given up to 4 places after the decimal in the SEM values. In order to evaluate
the fit of the parameter estimates, we compare the SEM to the estimated value
and calculate a ``normalized'' SEM which is defined as:
\begin{equation*}
    normalized \: SEM = \frac{SEM}{|estimated \: parameter|}
\end{equation*}
and is plotted in \autoref{fig:segnormsem}. The dotted lines in this plot do
not represent any relation between the parameters and are only used to easily
identify normalized SEM values belonging to the same segment. We can see that
the velocity feedback gain $K_v$ is least accurately estimated parameter and
that mass $M$, damping constant $B$, and spring constant $K$ are fit well to
the measured data. The estimated parameters values used in the SEM
normalization are given in \autoref{tab:segparam}. Units displayed in
\autoref{tab:segparam} and \autoref{tab:segsem} use units for a torsional
spring equation since the experiment measures rotations and not linear
displacements.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{segnormsem.eps}
    \caption{Normalized SEM for Estimated Parameters}
    \label{fig:segnormsem}
\end{figure}


% 2j
\subsection{Parameters Dependent on Background Torque}
From \autoref{fig:wristdata}, we see that the mean torque magnitude increases with each
segment. The estimated parameter values for each segment are shown in
\autoref{tab:segparam}. We can see that spring constant $K$ increases each
segment (or equivalently, as torque magnitude increases). We expect that $K$
increases with increasing torque; if the user is instructed to maintain a
larger torque value, the amount of torque exerted given the same angle
perturbation must be higher as the user must stiffen muscles in the wrist.
Larger torques result in larger accelerations of the wrist, resulting in larger
wrist velocities. For damping constant $B$, it is hard determine if it changes
with torque given the measured data. We see little change in in mass $M$ and
time delay $t_d$. As the mass of the system is not changing, nor the reation
time of the human subject (at least not significantly over the course of the
experiment), we expect these parameters to remain constant over all segments.
As velocity feedback $K_v$ and activation cut-off frequency $w$ have the
highest normalized SEM values, it is hard to determine how these parameters
change with background torque given the measured data.

% 2k
\subsection{VAF of Segments}
The Variance Account For (VAF) for each segment is given in
\autoref{tab:segvaf} and show a good match between the model and the measured
data. The measured and estimated rotation using a model with determine how
these parameters change with background torque with the measured Zooming in on
short time segments ($2$ seconds) in \autoref{fig:segrotzoom} shows a good fit
on signal shape although the magnitude differs by a small amount. This small
error between measured and estimated rotation corresponds with the high VAF
values.
\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|}
        \hline
        \nonumber & segment 1 & segment 2 & segment 3 & segment 4 \\
        \hline
        VAF & $81.9681$ & $87.0021$ & $92.3029$ & $90.4893$ \\
        \hline
    \end{tabular}
    \caption{VAF for Wrist with Velocity Feedback Model}
    \label{tab:segvaf}
\end{table}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{segrot.eps}
    \caption{Estimated and Measured Wrist Rotation}
    \label{fig:segrot}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{segrotzoom.eps}
    \caption{Zoomed Estimated and Measured Wrist Rotation}
    \label{fig:segrotzoom}
\end{figure}

% 2l
\subsection{Use of High-Pass Filters}
Due to temperature effects, we expect low frequency drift in the torque signal.
Without using a high-pass filter, the optimization will fit the model
parameters to this drift, resulting in an overfit of the data. As we know this
effect to be independent of the wrist model, we can minimize the effect of
drift by using a high-pass filter on the measured data. While the SEM and VAF
values may be higher with drift left in the data, this results in poorer
parameter estimates which can be seen when using an independent validation
dataset without drift.

% 2m
\subsection{Estimation of Parameters in Time Domain}
Simulating the model in the time domain and using the difference in the
measured and simulated output as the error results, we obtain the estimated
parameters listed in \autoref{tab:segparamhp} in the time domain columns.
Note that the signal is high-pass filtered for time domain optimization and the
parameters estimated with frequency domain optimization match the values from
\autoref{tab:segparam}.

% 2n
\subsection{Comparison of Frequency and Time Domain Estimates}
SEM and VAF are computed using time domain optimization and values for each
parameter are presented in the time domain columns of \autoref{tab:segsemhp}
and \autoref{tab:segvafhp}. While the SEM and VAF were previously calculated
using frequency domain optimization and are shown in \autoref{tab:segsem} and
\autoref{tab:segvaf} respectively, the VAF calculations have been recomputed
using high-pass filtered data in \autoref{tab:segvafhp} for comparison with
time-domain values. While most of the SEM values are lower in time domain
optimization, the VAF values for frequency domain optimization are higher for
each segment after high-pass filtering is used. This may be a result of the
different error functions used in time and frequency domains. A plot of the
normalized SEM values for parameter estimates in time domain and frequency
domain are is shown in \autoref{fig:segnormsemtf}. From this plot, we can see
that time domain results in better parameter estimates in terms of normalized
SEM, in addition to lower SEM values overall, as the estimated parameters are
quite close for both optimization domains.

\begin{sidewaystable}
    \centering
    \begin{tabular}{|l|r|r|r|r|r|r|r|r|}
        \hline
        \nonumber &
            \multicolumn{2}{c|}{segment 1} &
            \multicolumn{2}{c|}{segment 2} &
            \multicolumn{2}{c|}{segment 3} &
            \multicolumn{2}{c|}{segment 4} \\
        \hline
        \nonumber &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} \\
        \hline
        $\unit[M]{[kg\,m^2]}$ &
            $0.0030$ & $0.0027$ & $0.0029$ & $0.0027$ &
            $0.0026$ & $0.0026$ & $0.0023$ & $0.0026$ \\
        $\unit[B]{[\frac{kg\,m^2}{s\,rad}]}$ &
            $0.0371$ & $0.0508$ & $0.0408$ & $0.0489$ &
            $0.0595$ & $0.0595$ & $0.0670$ & $0.0583$ \\
        $\unit[K]{[N\,m/rad]}$ &
            $4.9675$ & $4.2514$ & $5.3029$ & $5.7312$ &
            $6.1462$ & $6.1855$ & $6.5311$ & $7.5809$ \\
        $\unit[K_v]{[rad/s]}$ &
            $-0.0782$ & $-0.0355$ & $-0.0775$ & $-0.0467$ &
            $-0.0659$ & $-0.0477$ & $-0.0660$ & $-0.0671$ \\
        $\unit[t_d]{[s]}$ &
            $0.0400$ & $0.0600$ & $0.0398$ & $0.0540$ &
            $0.0471$ & $0.0601$ & $0.0507$ & $0.0543$ \\
        $\unit[w]{[rad/s]}$ &
            $28.3671$ & $35.8176$ & $28.8176$ & $27.4777$ &
            $23.1918$ & $28.0485$ & $19.4152$ & $25.6516$ \\
        \hline
    \end{tabular}
    \caption{Estimated Parameters from Wrist with Velocity Feedback Model and
        High Pass Filtering for Time and Frequency Domain Optimization}
    \label{tab:segparamhp}
\end{sidewaystable}

\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|r|r|r|r|}
        \hline
        \nonumber &
            \multicolumn{2}{c|}{segment 1} &
            \multicolumn{2}{c|}{segment 2} &
            \multicolumn{2}{c|}{segment 3} &
            \multicolumn{2}{c|}{segment 4} \\
        \hline
        \nonumber &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} \\
        \hline
        $\unit[M]{[kg\,m^2]}$ &
            $0.0000$ & $0.0001$ & $0.0000$ & $0.0001$ &
            $0.0001$ & $0.0001$ & $0.0001$ & $0.0000$ \\
        $\unit[B]{[\frac{kg\,m^2}{s\,rad}]}$ &
            $0.0005$ & $0.0025$ & $0.0005$ & $0.0025$ &
            $0.0006$ & $0.0023$ & $0.0007$ & $0.0019$ \\
        $\unit[K]{[N\,m/rad]}$ &
            $0.0123$ & $0.0972$ & $0.0110$ & $0.1192$ &
            $0.0165$ & $0.1316$ & $0.0188$ & $0.1171$ \\
        $\unit[K_v]{[rad/s]}$ &
            $0.0011$ & $0.0056$ & $0.0012$ & $0.0089$ &
            $0.0029$ & $0.0100$ & $0.0041$ & $0.0110$ \\
        $\unit[t_d]{[s]}$ &
            $0.0004$ & $0.0057$ & $0.0004$ & $0.0059$ &
            $0.0007$ & $0.0062$ & $0.0011$ & $0.0037$ \\
        $\unit[w]{[rad/s]}$ &
            $0.2817$ & $4.6994$ & $0.2771$ & $3.5391$ &
            $0.4552$ & $4.0074$ & $0.6427$ & $2.6950$ \\
        \hline
    \end{tabular}
    \caption{SEM of Estimated Parameters from Wrist with Velocity Feedback
        Model and High Pass Filtering for Time and Frequency Domain
        Optimization}
    \label{tab:segsemhp}
\end{table}

\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|r|r|r|r|}
        \hline
        \nonumber &
            \multicolumn{2}{c|}{segment 1} &
            \multicolumn{2}{c|}{segment 2} &
            \multicolumn{2}{c|}{segment 3} &
            \multicolumn{2}{c|}{segment 4} \\
        \hline
        \nonumber &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} \\
        \hline
        VAF &
            $93.9951$ & $94.6912$ & $95.4617$ & $96.2253$ &
            $94.8857$ & $95.1913$ & $92.4736$ & $95.2300$ \\
        \hline
    \end{tabular}
    \caption{VAF for Wrist with Velocity Feedback Model and High Pass
        Filtering for Time and Frequency Domain Optimization}
    \label{tab:segvafhp}
\end{table}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{segnormsemtf.eps}
    \caption{Normalized SEM for Estimated Parameters in Time and Frequency
        Domain}
    \label{fig:segnormsemtf}
\end{figure}

% 2o
\subsection{High Frequency Noise in Time Domain Estimation}
High frequency noise has a lesser effect on parameter estimation in the time
domain. A least squares fit of the model parameters will minimize the error
residual between the simulated and measured data. As we assume that noise
has zero mean and is uncorrelated to the input and output signals, the optimal
parameters will also minimize the effect of noise on the error residual.

% 2p
\subsection{Validation Using a Second Dataset}
Validation of model parameters should always be done with a dataset different
than the one used to estimate the parameters. Since the optimization procedure
will return parameters that minimize error, using the same dataset for
parameter estimation and validation can result in overfitting of model
parameters; that is, fitting the the data to biases or noise present in the
data. Use of a separate, independent data set for validation reduces problems
of overfitting and gives insight on how model will generalize to independent or
unknown datasets. Calculation of VAF for verification dataset shows shows
similar values to the training dataset and the values are given in
\autoref{tab:segvafver}. As we take noise to be independent in the training and
validation datasets, it is unlikely that the model has been overfit to noise.

\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|r|r|r|r|}
        \hline
        \nonumber &
            \multicolumn{2}{c|}{segment 1} &
            \multicolumn{2}{c|}{segment 2} &
            \multicolumn{2}{c|}{segment 3} &
            \multicolumn{2}{c|}{segment 4} \\
        \hline
        \nonumber &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} &
            \multicolumn{1}{c|}{time} & \multicolumn{1}{c|}{freq.} \\
        \hline
        VAF &
            $94.6432$ & $95.4684$ & $93.7491$ & $94.0920$ &
            $93.9296$ & $94.4241$ & $92.1357$ & $95.3843$ \\
        \hline
    \end{tabular}
    \caption{VAF for Wrist with Velocity Feedback Model and High Pass
        Filtering for Time and Frequency Domain Optimization on Validation
        Dataset}
    \label{tab:segvafver}
\end{table}

% 2q
\subsection{Advantages and Disadvantages of Time Domain Identification}
From the experimental data, time domain identification produces better
estimates of the model parameters. However, it requires simulation of the
system at each iteration which is much slower than frequency domain analysis.
Furthermore, frequency domain modeling uses transfer functions which represent
the input and output relation of linear time-invariant systems, resulting in
poor modeling of nonlinear systems.

\end{document}
